# -*- coding: utf-8 -*-
"""Homeowrk5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gr24yg6XY_KvZk46VKat9Z0Qela1cMKs
"""

import numpy as np

from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

from nltk.corpus import stopwords
from nltk.tokenize import RegexpTokenizer
from nltk.stem.porter import PorterStemmer
from nltk.stem import WordNetLemmatizer

# Load data set with class labels and split into train and test set
data_Xy = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True)
category_names = data_Xy.target_names # text names of all categories
train_X, test_X, train_y, test_y = train_test_split(data_Xy.data, data_Xy.target, test_size=test_size_ratio, stratify=data_Xy.target)

vectorizer = TfidfVectorizer(stop_words='english', min_df=5, max_df=0.95)
train_vec = vectorizer.fit_transform(train_X)
test_vec = vectorizer.transform(test_X)
print (train_vec.shape, test_vec.shape)

# Dividing data
X_l, X_u, y_l, y_u = train_test_split(train_vec, train_y, test_size=10000, stratify=train_y)
print (X_l.shape, X_u.shape)

m=MultinomialNB()
m.fit(X_l, y_l)
MultinomialNB(alpha=1.0,fit_prior=True)
prediction1=m.predict(X_u)

print(classification_report(y_u,prediction1,target_names=category_names))

feature_names = np.asarray(vectorizer.get_feature_names())
for i, category in enumerate(category_names):
  top10 = np.argsort(m.coef_[i])[-10:]
  text = " ".join(feature_names[top10])
  print("%s: %s" % (category, text))

